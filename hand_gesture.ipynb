{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Flatten, Dense, Dropout\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import SGD\n",
    "#from keras.utils import to_categorical\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import backend as K\n",
    "#from theano import tensor as K\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/Apple/Downloads/hand_gesture'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The shape of the input to \"Flatten\" is not fully defined (got (512, 7, 0). Make sure to pass a complete \"input_shape\" or \"batch_input_shape\" argument to the first layer in your model.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-a047647b0acb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;31m# Load the VGG weigths\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVGG_16\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'vgg16_weights_th_dim_ordering_th_kernels.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-a047647b0acb>\u001b[0m in \u001b[0;36mVGG_16\u001b[0;34m(weights_path)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4096\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Apple/anaconda/lib/python3.6/site-packages/Keras-1.2.1-py3.6.egg/keras/models.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    330\u001b[0m                  output_shapes=[self.outputs[0]._keras_shape])\n\u001b[1;32m    331\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m             \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m                 raise TypeError('All layers in a Sequential model '\n",
      "\u001b[0;32m/Users/Apple/anaconda/lib/python3.6/site-packages/Keras-1.2.1-py3.6.egg/keras/engine/topology.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minbound_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m             \u001b[0;31m# This will call layer.build() if necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_inbound_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minbound_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m             \u001b[0;31m# Outputs were already computed when calling self.add_inbound_node.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minbound_nodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Apple/anaconda/lib/python3.6/site-packages/Keras-1.2.1-py3.6.egg/keras/engine/topology.py\u001b[0m in \u001b[0;36madd_inbound_node\u001b[0;34m(self, inbound_layers, node_indices, tensor_indices)\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;31m# creating the node automatically updates self.inbound_nodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m         \u001b[0;31m# as well as outbound_nodes on inbound layers.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mNode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minbound_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_output_shape_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Apple/anaconda/lib/python3.6/site-packages/Keras-1.2.1-py3.6.egg/keras/engine/topology.py\u001b[0m in \u001b[0;36mcreate_node\u001b[0;34m(cls, outbound_layer, inbound_layers, node_indices, tensor_indices)\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0;31m# TODO: try to auto-infer shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0;31m# if exception is raised by get_output_shape_for.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m             \u001b[0moutput_shapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutbound_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_output_shape_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0moutput_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutbound_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Apple/anaconda/lib/python3.6/site-packages/Keras-1.2.1-py3.6.egg/keras/layers/core.py\u001b[0m in \u001b[0;36mget_output_shape_for\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    473\u001b[0m             raise ValueError('The shape of the input to \"Flatten\" '\n\u001b[1;32m    474\u001b[0m                              \u001b[0;34m'is not fully defined '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m                              \u001b[0;34m'(got '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m                              \u001b[0;34m'Make sure to pass a complete \"input_shape\" '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m                              \u001b[0;34m'or \"batch_input_shape\" argument to the first '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The shape of the input to \"Flatten\" is not fully defined (got (512, 7, 0). Make sure to pass a complete \"input_shape\" or \"batch_input_shape\" argument to the first layer in your model."
     ]
    }
   ],
   "source": [
    "# VGG model definition\n",
    "def VGG_16(weights_path=None):\n",
    "    model = Sequential()\n",
    "    model.add(ZeroPadding2D((1,1),input_shape=(224,224,3)))\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1000, activation='softmax'))\n",
    "\n",
    "    if weights_path:\n",
    "        model.load_weights(weights_path)\n",
    "\n",
    "    return model\n",
    "\n",
    "# Load the VGG weigths\n",
    "\n",
    "#theano\n",
    "model = VGG_16('vgg16_weights_th_dim_ordering_th_kernels.h5')\n",
    "\n",
    "#tensorflow\n",
    "model = VGG_16('vgg16_weights_tf_dim_ordering_tf_kernels.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "size = 224\n",
    "\n",
    "path = '/Users/Apple/Downloads/hand_gesture/Triesch'\n",
    "\n",
    "def read_image(f):\n",
    "    try: #read only jpgs (Add this)\n",
    "        im = Image.open(f)\n",
    "        im = im.resize((size, size), PIL.Image.NEAREST)\n",
    "        im = np.asarray(im, dtype='float64')\n",
    "        if len(im.shape)==2:\n",
    "            im = im.reshape(im.shape[0],im.shape[1],1)\n",
    "            im = im.repeat(3,axis=2)\n",
    "        if im.shape[2]!=3:\n",
    "            im = im[:,:,:3]\n",
    "        im[:,:,0] -= 103.939\n",
    "        im[:,:,1] -= 116.779\n",
    "        im[:,:,2] -= 123.68\n",
    "        im = im.reshape(1,224,224,3)\n",
    "        return(im)\n",
    "    except:\n",
    "        print(f,im.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "# Basic Check of read_image\n",
    "im = read_image('/Users/Apple/Downloads/hand_gesture/Triesch/bfritza2.pgm')\n",
    "print(im.shape)\n",
    "# model.layers[32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# with a Sequential model, get output of only 33rd layer\n",
    "get_33rd_layer_output = K.function([model.layers[0].input],\n",
    "                                  [model.layers[32].output])\n",
    "layer_output = get_33rd_layer_output([im])[0]\n",
    "#print(layer_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "719\n"
     ]
    }
   ],
   "source": [
    "img_files = []\n",
    "path = '/Users/Apple/Downloads/hand_gesture/Triesch/'\n",
    "for root, dirs, files in os.walk(path):\n",
    "   img_files.extend(files)\n",
    "print(len(img_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of images: 719\n",
      "Sample images taken: 719\n",
      "['szadela2.pgm', 'haloosc1.pgm', 'haloosg2.pgm', 'hnevenl1.pgm', 'pleuchl3.pgm', 'hnevenb2.pgm', 'saginsa3.pgm', 'nkruegb2.pgm', 'hnevena1.pgm', 'ermaelb2.pgm']\n",
      "719\n"
     ]
    }
   ],
   "source": [
    "n_files = len(img_files)\n",
    "print('Total number of images:', n_files)\n",
    "\n",
    "#train_size = 2000\n",
    "#for demo\n",
    "train_size = 10\n",
    "sample_size = max(n_files,train_size)\n",
    "print('Sample images taken:', sample_size)\n",
    "sample = [img_files[i] for i in np.random.choice(len(img_files),size=sample_size, replace=False)]\n",
    "print(sample[:10])\n",
    "print(len(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "[0, 2, 4, 7, 7, 1, 0, 1, 0, 1, 7, 7, 4, 3, 1, 9, 9, 8, 1, 2, 7, 8, 4, 6, 8, 3, 4, 7, 8, 7, 8, 1, 2, 0, 3, 4, 7, 3, 7, 7, 0, 3, 4, 0, 8, 6, 4, 8, 1, 8, 4, 2, 2, 8, 0, 7, 2, 3, 4, 7, 1, 2, 4, 9, 3, 2, 6, 7, 3, 1, 8, 5, 4, 9, 4, 0, 0, 9, 5, 0, 7, 3, 7, 8, 9, 1, 9, 8, 5, 1, 2, 1, 8, 0, 3, 5, 1, 7, 6, 8]\n"
     ]
    }
   ],
   "source": [
    "file = \"szadela2.pgm\"\n",
    "print(file[6])\n",
    "y = []\n",
    "for file in sample[:100]:\n",
    "    y.extend()\n",
    "print(y)\n",
    "# l = [1, 2, 3, 4, 5]\n",
    "# ['yes' if v == 1 else 'no' if v == 2 else 'idle' for v in l]\n",
    "# ['yes', 'no', 'idle', 'idle', 'idle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading train images ...\n",
      "Read 0 images\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'get_33rd_layer_output' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-fb745530d450>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Read {} images'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_33rd_layer_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     y_train.extend([0 if file[6]=='a' else \n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_33rd_layer_output' is not defined"
     ]
    }
   ],
   "source": [
    "# Read the train images \n",
    "i=0\n",
    "x_train = []\n",
    "y_train = []\n",
    "print('Reading train images ...')\n",
    "for file in sample[:14600]:\n",
    "    if(i%600==0):\n",
    "        print('Read {} images'.format(i))\n",
    "    im = read_image(path+file)\n",
    "    temp = get_33rd_layer_output([im])[0]\n",
    "    x_train.append(temp[0])\n",
    "    y_train.extend([0 if file[6]=='a' else \n",
    "              1 if file[6]=='b' else \n",
    "              2 if file[6]=='c' else \n",
    "              3 if file[6]=='d' else\n",
    "              4 if file[6]=='g' else\n",
    "              5 if file[6]=='h' else\n",
    "              6 if file[6]=='i' else\n",
    "              7 if file[6]=='l' else\n",
    "              8 if file[6]=='v' else 9])\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read the val images \n",
    "j=0\n",
    "x_val = []\n",
    "y_val = []\n",
    "print('Reading val images ...')\n",
    "for file in sample[14600:]:\n",
    "    if(j%600==0):\n",
    "        print('Read {} images'.format(j))\n",
    "    im = read_image('/home/s_jaysetty/Insofe_Cluster/train_samples_kaggle/'+file)\n",
    "    temp = get_33rd_layer_output([im])[0]\n",
    "    x_val.append(temp[0])\n",
    "    y_val.extend([0 if file[:3]=='cat' else 1])\n",
    "    j+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(type(x_train), type(y_train))\n",
    "print(type(x_val), type(y_val))\n",
    "# print(x_train.shape, y_train.shape)\n",
    "\n",
    "x_train = np.array(x_train)\n",
    "print(x_train.shape, 'x_train Shape')\n",
    "\n",
    "# y_train = to_categorical(y_train)\n",
    "y_train = np.array(y_train)\n",
    "print(y_train.shape, 'y_train Shape')\n",
    "\n",
    "x_val = np.array(x_val)\n",
    "print(x_val.shape, 'x_train Shape')\n",
    "\n",
    "# y_train = to_categorical(y_train)\n",
    "y_val = np.array(y_val)\n",
    "print(y_val.shape, 'y_val Shape')\n",
    "\n",
    "print(type(x_train), type(y_train))\n",
    "print(type(x_val), type(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add the MLP Layer\n",
    "\n",
    "mlp = Sequential()\n",
    "mlp.add(Dense(256, input_dim=4096, activation='relu'))\n",
    "mlp.add(Dropout(0.5))\n",
    "mlp.add(Dense(256, activation='relu'))\n",
    "mlp.add(Dropout(0.5))\n",
    "mlp.add(Dense(1, activation='sigmoid'))#try dense as 1 and sigmoid\n",
    "mlp.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#adam = Adam(lr=0.1)\n",
    "mlp.compile(optimizer='Adam', \n",
    "            loss='binary_crossentropy', \n",
    "            metrics=['acc'])\n",
    "\n",
    "mlp.fit(x_train, y_train, nb_epoch=20, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_files_test = []\n",
    "for root, dirs, files in os.walk('/home/s_jaysetty/Insofe_Cluster/test/'):\n",
    "    img_files_test.extend(files)\n",
    "\n",
    "n_files_test = len(img_files_test)\n",
    "print('Total number of images:', n_files_test)\n",
    "\n",
    "test_size = 100\n",
    "sample_size_test = max(n_files_test,test_size)\n",
    "print('Sample images taken:', sample_size_test)\n",
    "sample_test = [img_files_test[i] for i in np.random.choice(len(files),size=sample_size_test, replace=False)]\n",
    "print(sample_test[:10])\n",
    "print(len(sample_test))\n",
    "\n",
    "i=0\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "print('Reading test images ...')\n",
    "for file in img_files_test:\n",
    "    if(i%200==0):\n",
    "        print('Read {} images'.format(i))\n",
    "    im = read_image('/home/s_jaysetty/Insofe_Cluster/test/'+file)\n",
    "#     y_test.extend([0 if file[:3]=='cat' else 1])\n",
    "    temp = get_33rd_layer_output([im])[0]\n",
    "    x_test.append(temp[0])\n",
    "    i+=1\n",
    "\n",
    "x_test = np.array(x_test)\n",
    "print(x_test.shape, 'x_test Shape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = mlp.predict(x_test, batch_size=50)\n",
    "print(prediction[:3])\n",
    "print(prediction.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_class = mlp.predict_classes(x_test, batch_size=50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
